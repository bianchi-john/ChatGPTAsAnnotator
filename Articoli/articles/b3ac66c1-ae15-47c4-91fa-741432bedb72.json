{"id": "b3ac66c1-ae15-47c4-91fa-741432bedb72", "meta_dataset": "", "meta_language": "Italian", "meta_label": "Group 2", "meta_title": "L\u2019intelligenza artificiale sospesa fra sogni e incubi", "url": "https://www.editorialedomani.it/tecnologia/tecnologia-realta-virtuale-robotica-intelligenza-artificiale-yh27tz02", "text": "Realt\u00e0 virtuale e robotica, ma anche simulazione della mente attraverso l\u2019utilizzo della tecnologia. Mentre tutto questo non \u00e8 pi\u00f9 fantascienza, rimangono gli interrogativi su quali siano i rischi per l\u2019uomo\n\nNon l\u2019aspetto muscolare dell\u2019azione, come nella robotica, n\u00e9 quello viscerale del divertimento, come nella realt\u00e0 virtuale, ma l\u2019attivit\u00e0 intellettuale esercitata dal cervello e dalla mente.\n\nL\u2019intelligenza artificiale sta rapidamente entrando nelle nostre vite, e spesso i media ne parlano confondendo fra loro progetti e tecnologie di natura completamente diversa, che hanno per\u00f2 un aspetto comune: l\u2019uso delle macchine per simulare o emulare artificialmente una realt\u00e0 naturale. I principali filoni sono tre: la robotica, l\u2019intelligenza artificiale e la realt\u00e0 virtuale, che si concentrano rispettivamente sulla simulazione del corpo, della mente e dell\u2019ambiente esterno.\n\nRobot e gli altri\n\nLa robotica prende il nome dal romanzo R.u.r. (1920) di Karel \u010capek, il cui titolo era un acronimo per Robot universali di Rossum: in cecoslovacco la parola robota significa semplicemente \u201clavoratore forzato\u201d, e i protagonisti della storia erano appunto delle macchine umanoidi senza volont\u00e0, poco dopo rappresentate nel film Metropolis (1927) di Fritz Lang. Nei paesi filoamericani sono invece pi\u00f9 noti i racconti Io, robot (1950) di Isaac Asimov, e l\u2019omonimo film da essi tratto nel 2004: in uno dei racconti sono enunciate le famose tre leggi della robotica, che impongono ai robot di non danneggiare l\u2019uomo, di obbedirlo e di auto-preservarsi.\n\nL\u2019intelligenza artificiale ha invece raggiunto il grande pubblico pi\u00f9 tardi, soprattutto grazie al computer Hal del film 2001: Odissea nello spazio (1968) di Stanley Kubrick, tratto dall\u2019omonimo romanzo di Arthur Clarke. Ma fin dalla sua nascita il computer \u00e8 stato pensato come un \u201ccervello elettronico\u201d, le cui potenzialit\u00e0 si estendevano enormemente al di l\u00e0 delle semplici competenze numeriche. Gi\u00e0 nel 1950 Alan Turing, che l\u2019aveva inventato nel 1936, si chiedeva se fosse possibile insegnargli a giocare bene a scacchi, o addirittura a farlo conversare in maniera indistinguibile da un uomo, e propose di considerare intelligenti i computer in grado di superare questo test.\n\nAl contrario, la robotica agli inizi non era un\u2019impresa informatica, ma meccanica, con antichi e illustri precedenti: gli automi dell\u2019imperatore Chin, la Galatea di Pigmalione, le teste parlanti di Alberto Magno, il Golem del rabbino L\u00f6w, l\u2019homunculus di Paracelso, l\u2019anatra di Vaucanson, il giocatore di scacchi del barone Von Kempelen, il Frankenstein di Mary Shelley, le macchine ribelli di Erewhon, eccetera. Ma coniugando la robotica con l\u2019intelligenza artificiale si arriva a formulare il sogno della produzione di macchine antropomorfe indistinguibili dall\u2019uomo, come quelle rese popolari dal film Blade Runner (1982) di Ridley Scott.\n\nQuest\u2019ultimo era basato sulle visioni di Philip Dick, che lui stesso riassunse nel discorso L\u2019androide e l\u2019umano (1972) pronunciato al quinto Convegno di fantascienza di Vancouver: \u00abUn giorno forse vedremo un uomo sparare a un androide appena uscito da una fabbrica di creature artificiali e l\u2019androide, con grande sorpresa dell\u2019uomo, prender\u00e0 a sanguinare. Il robot sparer\u00e0 di rimando e, con sua gran sorpresa, vedr\u00e0 una voluta di fumo levarsi dalla pompa elettrica che si trova al posto del cuore dell\u2019uomo. Sar\u00e0 un grande momento di verit\u00e0 per entrambi\u00bb.\n\nLa realt\u00e0 virtuale costituisce il terzo e ultimo passo del percorso di meccanizzazione del mondo, e tende a ricreare ambienti artificiali indistinguibili da quelli naturali, allo stesso modo in cui gli androidi sono indistinguibili dagli uomini. Al pubblico l\u2019idea \u00e8 arrivata con il romanzo Il neuromante (1984) di William Gibson, e soprattutto con i due film Il tagliaerbe (1992) di Brett Leonard e Matrix (1999) delle sorelle Wachowski: il primo introduceva l\u2019idea della connessione multimediale al computer tramite una tuta sensoriale per le percezioni e un dispositivo a snodo cardanico per i movimenti, mentre il secondo mostrava come poteva apparire la vita all\u2019interno di un mondo virtuale generato dal computer.\n\nNaturalmente, anche per la realt\u00e0 virtuale ci sono precedenti illustri. Anzi, si pu\u00f2 dire che in fondo tutto l\u2019entertainment (sport, gioco, religione, mitologia, psicanalisi, arte, filosofia, letteratura, teatro, opera, radio, cinema e televisione) costituisce un\u2019unica grande impresa collettiva di produzione e fruizione di realt\u00e0 virtuali nelle quali l\u2019essere umano si immerge, rischiando di annegarci: non a caso si parla di sospensione dell\u2019incredulit\u00e0, in generale, e di illusione filmica, in particolare, per lo stato psicologico di chi vi partecipa o ne fruisce, a met\u00e0 strada tra la pura allucinazione e la piena coscienza.\n\nCome gi\u00e0 per la robotica, anche per la realt\u00e0 virtuale la differenza la fa ancora una volta il computer. Se per i media convenzionali la libera uscita nella virtualit\u00e0 avveniva a piccole dosi, eccetto in casi patologici quali la ludopatia, il misticismo o il bovarismo, dalla televisione in poi si pu\u00f2 ormai parlare di assuefazione, soprattutto ai videogiochi, alla rete e ai social network. L\u2019overdose arriver\u00e0 dapprima con la realt\u00e0 aumentata dei Google glasses, e poi con la realt\u00e0 virtuale dei visori e delle tute sensoriali, che causeranno la transizione dagli esseri coscienti del vecchio mondo a quelli ipnotizzati descritti nel romanzo Il mondo nuovo (1932) di Aldous Huxley.\n\nIntelligenza artificiale\n\nCome si pu\u00f2 intuire da questi brevi cenni, la robotica \u00e8 soprattutto un\u2019impresa di produzione, ormai largamente diffusa nelle fabbriche e nelle industrie, bench\u00e9 pi\u00f9 nella forma di utili arti meccanici, che non di inutili robot antropomorfi. La realt\u00e0 virtuale \u00e8 invece soprattutto un\u2019impresa di distrazione, come dimostra l\u2019interessamento nel campo di Mark Zuckerberg: emblematica, a questo proposito, la foto da lui postata su Facebook il 21 febbraio 2016, che lo mostra al Congresso mondiale del cellulare di Barcellona alla stregua di un personaggio di Dick, unico a vederci chiaro senza visore, in una platea di gente immersa solipsisticamente nella realt\u00e0 virtuale.\n\nDelle tre imprese di meccanizzazione del reale, la pi\u00f9 stimolante e intrigante \u00e8 sicuramente l\u2019intelligenza artificiale, che ci permette di guardare allo specchio il nostro lato pi\u00f9 profondo e complesso: non l\u2019aspetto muscolare dell\u2019azione, come nella robotica, n\u00e9 quello viscerale del divertimento, come nella realt\u00e0 virtuale, ma l\u2019attivit\u00e0 intellettuale esercitata dal cervello e dalla mente. A seconda che si intendano riprodurre soltanto gli effetti del nostro pensiero, o anche i processi che portano alla loro formazione, si parla di simulazione o di emulazione. E a seconda che ci si concentri su alcuni compiti mentali specifici, o si punti invece a una abilit\u00e0 universale, si parla di intelligenza artificiale debole o forte.\n\nI successi raggiunti nel corso dei primi decenni successivi al Congresso di Darmouth del 1956, nel quale si posero le basi per il progetto dell\u2019intelligenza artificiale, riguardano soprattutto le simulazioni deboli. Nel 1966 il programma Eliza di Joseph Weizenbaum mostr\u00f2 quanto sia facile imitare efficacemente le conversazioni che uno psicanalista intrattiene con un paziente. Nel 1970 il sistema esperto Mycin inaugur\u00f2 la lista dei programmi interattivi che permettono di effettuare diagnosi e prognosi di malattie specifiche.\n\nNel 1976 Kenneth Appel e Wolfgang Hakel dimostrarono con un massiccio uso del computer il teorema dei quattro colori, primo esempio di verit\u00e0 non verificabile dal solo cervello dell\u2019uomo. E nel 1997 il programma Deep Blue batt\u00e9 per la prima volta in un torneo ufficiale il campione mondiale di scacchi in carica: oggi i grandi maestri non sono pi\u00f9 competitivi contro i programmi, cos\u00ec come gli atleti olimpici non lo sono pi\u00f9 da tempo contro le automobili.\n\nNegli ultimi decenni si sono affrontate le difficolt\u00e0 pi\u00f9 sottili dell\u2019intelligenza artificiale, a partire dalla simulazione della capacit\u00e0 istintiva di riconoscimento di volti, motivi musicali, opere d\u2019arte e calligrafie: non a caso, ancor oggi il test per dimostrare in rete che non si \u00e8 un robot consiste appunto nel riconoscere lettere scritte in maniera strana o distorta. La novit\u00e0 in questo campo sta nelle tecniche di deep learning, \u201capprendimento profondo\u201d, basate sull\u2019uso delle reti neurali introdotte nel 1943 dal neurofisiologo Warren McCulloch e dal matematico Walter Pitts, a loro volta modellate sulla struttura del sistema nervoso: un esempio recente \u00e8 il programma AlphaZero, che in poche ore di autoapprendimento ha raggiunto il livello del programma campione mondiale di scacchi (Stockfish), giocando in maniera quasi umana.\n\nUna nuova \u00e8ra\n\nL\u2019intelligenza artificiale sta dunque uscendo dall\u2019\u00e8ra della bruta simulazione del pensiero, ed entrando nell\u2019\u00e8ra della sua sottile emulazione, e arriver\u00e0 forse a rispondere a una serie di profonde domande sull\u2019uomo e sul computer. Ad esempio, si pu\u00f2 imitare la complessa biochimica del cervello tramite la semplice elettronica? Un cervello isolato pu\u00f2 funzionare, anche senza un corpo? E si pu\u00f2 imitare la neocorteccia, senza imitare anche un cervello rettiliano sottostante? Inoltre, si possono, o addirittura si devono, insegnare valori umani a una macchina? E si pu\u00f2 evitare che una macchina sviluppi valori propri, alternativi o contrapposti ai nostri?\n\nIl che ci conduce a pensare ai possibili rischi che possono derivare dallo sviluppo dell\u2019intelligenza artificiale. Rischi teorici, derivanti dall\u2019impossibilit\u00e0 di sapere se un computer far\u00e0 sempre e soltanto tutto ci\u00f2 che gli ordiniamo di fare, perch\u00e9 il problema della verifica di correttezza dei programmi \u00e8 dimostrabilmente indecidibile. E rischi pratici, derivanti ad esempio da manipolazioni fraudolente di dati, come negli scandali della Telecom nel 2006, o di Facebook e di Cambridge Analytica nel 2019. O da errori nelle interpretazioni dei dati, come nelle false allerte di attacchi nucleari nel 1983 in Unione Sovietica e nel 2018 alle Hawaii, o nel flash crash della borsa di New York nel 2010.\n\nMa i rischi maggiori derivano dalla Superintelligenza, come la chiama Nick Bostrom in un inquietante libro del 2014, consigliato da Bill Gates e Elon Musk. Cio\u00e8, da un\u2019intelligenza artificiale molto superiore a quella umana, che sfruttata da individui o governi malintenzionati, o addirittura sfuggita al controllo umano, potrebbe diventare ancora pi\u00f9 pericolosa del nucleare o del clima, che invece oggi monopolizzano le preoccupazioni degli ingenui."}